{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af71cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import asyncio\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor,  as_completed\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import cloudscraper\n",
    "from htmldate import find_date\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f72e951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a25212123b47ea87262962103abaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Company:', layout=Layout(width='300px'), options=('Tesla', 'NVIDIA', 'Apple', 'Microsoft…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "companies = {\n",
    "    \"Tesla\": \"tesla-motors\",\n",
    "    \"NVIDIA\": \"nvidia-corp\",\n",
    "    \"Apple\": \"apple-computer-inc\",\n",
    "    \"Microsoft\": \"microsoft-corp\",\n",
    "    \"Amazon\": \"amazon-com-inc\",\n",
    "    \"Google\": \"google-inc\",\n",
    "    \"Meta\": \"facebook-inc\",\n",
    "    \"Netflix\": \"netflix,-inc.\",\n",
    "    \"AMD\": \"adv-micro-device\",\n",
    "}\n",
    "\n",
    "# Create a dropdown widget\n",
    "company_dropdown = widgets.Dropdown(\n",
    "    options=list(companies.keys()),\n",
    "    value='Tesla',\n",
    "    description='Company:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '300px'}\n",
    ")\n",
    "\n",
    "display(company_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b193b940",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 41\u001b[0m, in \u001b[0;36mfetch_page\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m     40\u001b[0m r \u001b[38;5;241m=\u001b[39m scraper\u001b[38;5;241m.\u001b[39mget(url, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     42\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(r\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.investing.com/equities/tesla-motors-news/1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(all_links)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 99\u001b[0m     links \u001b[38;5;241m=\u001b[39m robust_scrape()\n",
      "Cell \u001b[0;32mIn[28], line 62\u001b[0m, in \u001b[0;36mrobust_scrape\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrobust_scrape\u001b[39m():\n\u001b[0;32m---> 62\u001b[0m     first \u001b[38;5;241m=\u001b[39m fetch_page(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     63\u001b[0m     PER_PAGE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(first)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m PER_PAGE \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[28], line 56\u001b[0m, in \u001b[0;36mfetch_page\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m MAX_RETRIES:\n\u001b[1;32m     55\u001b[0m     backoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (attempt \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom()\n\u001b[0;32m---> 56\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(backoff)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_RETRIES\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "COMPANY = companies[company_dropdown.value]\n",
    "MAX_PAGE    = 2\n",
    "MAX_WORKERS = 50              \n",
    "MAX_RETRIES = 8              \n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"none\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Referer\": \"https://www.investing.com/\",\n",
    "    \"DNT\": \"1\"\n",
    "}\n",
    "\n",
    "scraper = cloudscraper.create_scraper(\n",
    "    browser={\n",
    "        'browser': 'chrome',\n",
    "        'platform': 'darwin',\n",
    "        'mobile': False\n",
    "    },\n",
    "    delay=2\n",
    ")\n",
    "\n",
    "def fetch_page(page: int):\n",
    "    global ticker\n",
    "    #Equity\n",
    "    url = f\"https://www.investing.com/equities/{COMPANY}-news/{page}\"\n",
    "    #Index\n",
    "    #url = f\"https://www.investing.com/indices/nq-100-news/{page}\"\n",
    "    #url = f\"https://www.investing.com/indices/us-spx-500-news/{page}\"\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = scraper.get(url, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            soup = BeautifulSoup(r.text, \"lxml\")\n",
    "            h1_tag = soup.find('h1', class_='mb-2.5') # Use a specific class or combination of classes for robustness\n",
    "            full_text = h1_tag.text.strip()\n",
    "            match = re.search(r'\\(([^)]+)\\)', full_text)\n",
    "            ticker = match.group(1)\n",
    "                    \n",
    "            anchors = soup.select(\n",
    "                'ul[data-test=\"news-list\"] '\n",
    "                'li article a[data-test=\"article-title-link\"]'\n",
    "            )\n",
    "            return [a[\"href\"] for a in anchors if a.has_attr(\"href\")]\n",
    "        except Exception as e:\n",
    "            if attempt < MAX_RETRIES:\n",
    "                backoff = 2 ** (attempt - 1) + random.random()\n",
    "                time.sleep(backoff)\n",
    "            else:\n",
    "                print(f\"Page {page} failed after {MAX_RETRIES}: {e}\")\n",
    "    return []\n",
    "\n",
    "def robust_scrape():\n",
    "    first = fetch_page(1)\n",
    "    PER_PAGE = len(first)\n",
    "    if PER_PAGE == 0:\n",
    "        raise RuntimeError(\"Failed to fetch the first page. Please check headers or cookies and try again.\")\n",
    "    print(f\"Detected {PER_PAGE} links per page, expecting {PER_PAGE * MAX_PAGE} total\")\n",
    "\n",
    "    results = {1: first}\n",
    "    pages = list(range(2, MAX_PAGE + 1))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:\n",
    "        futures = {pool.submit(fetch_page, p): p for p in pages}\n",
    "        for fut in as_completed(futures):\n",
    "            p = futures[fut]\n",
    "            results[p] = fut.result()\n",
    "\n",
    "        for round in range(1, MAX_RETRIES + 1):\n",
    "            bad = [p for p, links in results.items() if len(links) != PER_PAGE]\n",
    "            if not bad:\n",
    "                print(f\"All pages OK after {round-1} retries\")\n",
    "                break\n",
    "            print(f\"Retry round {round} for pages: {bad}\")\n",
    "            futures = {pool.submit(fetch_page, p): p for p in bad}\n",
    "            for fut in as_completed(futures):\n",
    "                p = futures[fut]\n",
    "                results[p] = fut.result()\n",
    "        else:\n",
    "            print(\"Retry limit reached; some pages may still be incomplete.\")\n",
    "\n",
    "    total_fetched = sum(len(links) for links in results.values())\n",
    "    expected = PER_PAGE * MAX_PAGE\n",
    "    print(f\"Total links fetched (including duplicates): {total_fetched} (expected {expected})\")\n",
    "\n",
    "    all_links = set(link for links in results.values() for link in links)\n",
    "    print(f\"Final: got {len(all_links)} unique URLs (expected {expected})\")\n",
    "    return list(all_links)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    links = robust_scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf873f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fetch][3/20][ok]\n",
      "[Fetch][8/20][ok]\n",
      "[Fetch][9/20][ok]\n",
      "[Fetch][14/20][ok]\n",
      "[Fetch][1/20][ok]\n",
      "[Fetch][7/20][ok]\n",
      "[Fetch][18/20][ok]\n",
      "[Fetch][12/20][ok]\n",
      "[Fetch][6/20][ok]\n",
      "[Fetch][15/20][ok]\n",
      "[Fetch][19/20][ok]\n",
      "[Fetch][10/20][ok]\n",
      "[Fetch][5/20][ok]\n",
      "[Fetch][16/20][ok]\n",
      "[Fetch][4/20][ok]\n",
      "[Fetch][2/20][ok]\n",
      "[Fetch][17/20][ok]\n",
      "[Fetch][20/20][ok]\n",
      "[Fetch][11/20][ok]\n",
      "[Fetch][13/20][ok]\n",
      "[Process][1/20] https://www.investing.com/news/stock-market-news/xiaomi-launches-yu7-priced-from-253500-yuan-challenging-teslas-model-y-4113027\n",
      "[Process][2/20] https://www.investing.com/news/pro/benchmark-maintains-tesla-at-buy-with-a-price-target-of-47500-4112105\n",
      "[Process][3/20] https://www.investing.com/news/pro/citi-yu7-launch-positive-for-xiaomi-followed-by-hesaicatlnvidia-while-negative-to-teslaxpeng-432SI-4113464\n",
      "[Process][4/20] https://www.investing.com/news/stock-market-news/shares-of-chinas-xiaomi-surge-after-launch-of-electric-vehicle-yu7-4113887\n",
      "[Process][5/20] https://www.investing.com/news/analyst-ratings/tesla-price-target-raised-to-475-from-350-at-benchmark-on-robotaxi-launch-93CH-4113049\n",
      "[Process][6/20] https://www.investing.com/news/stock-market-news/tesla-target-lifted-to-475-at-benchmark-after-robotaxi-launch-4112984\n",
      "[Process][7/20] https://www.investing.com/news/stock-market-news/chinese-ev-shares-fall-as-xiaomi-yu7-launch-heralds-more-competition-4113926\n",
      "[Process][8/20] https://www.investing.com/news/cryptocurrency-news/bitcoin-price-today-steady-at-107k-institutional-demand-in-focus-4111687\n",
      "[Process][9/20] https://www.investing.com/news/pro/tesla-executive-and-musk-confidant-omead-afshar-departs-company--bloomberg-432SI-4113255\n",
      "[Process][10/20] https://www.investing.com/news/stock-market-news/xiaomi-shares-hit-record-high-on-strong-yu7-ev-preorders-4113895\n",
      "[Process][11/20] https://www.investing.com/news/economy-news/trading-day-markets-run-it-hot-4113766\n",
      "[Process][12/20] https://www.investing.com/news/stock-market-news/tesla-executive-omead-afshar-departs-amid-challenging-period--bloomberg-93CH-4113269\n",
      "[Process][13/20] https://www.investing.com/news/stock-market-news/tesla-executive-elon-musk-confidant-leaves-ev-maker-bloomberg-news-reports-4113297\n",
      "[Process][14/20] https://www.investing.com/news/stock-market-news/teslas-robotaxi-peppered-with-driving-mistakes-in-texas-tests-4111236\n",
      "[Process][15/20] https://www.investing.com/news/pro/tesla-hr-executive-jenna-ferrua-is-said-to-depart-company--bloomberg-432SI-4113292\n",
      "[Process][16/20] https://www.investing.com/news/economy-news/futures-edge-higher-trump-on-possible-powell-replacement--whats-moving-markets-4111795\n",
      "[Process][17/20] https://www.investing.com/news/pro/charlotte-drops-tesla-from-approved-city-vehicle-list-alleging-safety-issues--nyp-432SI-4113243\n",
      "[Process][18/20] https://www.investing.com/news/stock-market-news/pony-ai-stock-surges-after-nyt-reports-uberkalanick-talks-for-acquisition-4113524\n",
      "[Process][19/20] https://www.investing.com/news/stock-market-news/lyft-taps-drivers-for-strategic-input-to-help-navigate-robotaxi-rollout-4112833\n",
      "[Process][20/20] https://www.investing.com/news/cryptocurrency-news/deribit-and-signalplus-launch-the-summer-chase-trading-competition-2025-featuring-a-300000-usdc-prize-pool-4111728\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "FETCH_WORKERS = min(32, os.cpu_count() * 4)  \n",
    "PROCESS_WORKERS = os.cpu_count() or 4\n",
    "MAX_FETCH_RETRIES = 5                      \n",
    "RETRY_DELAY = 1                             \n",
    "TICKER = ticker\n",
    "scraper = cloudscraper.create_scraper()\n",
    "\n",
    "def is_placeholder(html: str) -> bool:\n",
    "    lower = html.lower() if html else \"\"\n",
    "    return (\n",
    "        'temporarily down for maintenance' in lower\n",
    "        or 'just a moment' in lower\n",
    "        or \"we're temporarily down\" in lower\n",
    "    )\n",
    "\n",
    "def safe_find_datetime(url, html_content=None):\n",
    "    try:\n",
    "        # Strategy 1: Use htmldate library to extract date from URL\n",
    "        dt = find_date(url)\n",
    "        if dt:\n",
    "            return dt, \"00:00\"  # Return with default time if date found\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if html_content:\n",
    "        # Strategy 2: Look for American format with AM/PM\n",
    "        m = re.search(r\"(\\d{1,2}/\\d{1,2}/\\d{4}),\\s*(\\d{1,2}:\\d{2}\\s*(?:AM|PM))\", html_content)\n",
    "        if m:\n",
    "            ds, ts = m.groups()\n",
    "            try:\n",
    "                dt = datetime.strptime(f\"{ds}, {ts}\", \"%m/%d/%Y, %I:%M %p\")\n",
    "                return dt.strftime(\"%Y-%m-%d\"), dt.strftime(\"%H:%M\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Strategy 3: Look for numeric dates with 24-hour time format\n",
    "        m = re.search(r\"(\\d{2}/\\d{2}/\\d{4}),\\s*(\\d{2}:\\d{2})\", html_content)\n",
    "        if m:\n",
    "            ds, ts = m.groups()\n",
    "            # Try both European and American date formats\n",
    "            for fmt in (\"%d/%m/%Y, %H:%M\", \"%m/%d/%Y, %H:%M\"):\n",
    "                try:\n",
    "                    dt = datetime.strptime(f\"{ds}, {ts}\", fmt)\n",
    "                    return dt.strftime(\"%Y-%m-%d\"), dt.strftime(\"%H:%M\")\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d\"), now.strftime(\"%H:%M\")\n",
    "\n",
    "def fetch_html(url, idx, total):\n",
    "    for attempt in range(1, MAX_FETCH_RETRIES + 1):\n",
    "        try:\n",
    "            resp = scraper.get(url, timeout=30)\n",
    "            html = resp.text\n",
    "            if is_placeholder(html):\n",
    "                raise RuntimeError('Placeholder')\n",
    "                \n",
    "            print(f\"[Fetch][{idx}/{total}][ok]\")\n",
    "            return url, html\n",
    "            \n",
    "        except Exception:\n",
    "            print(f\"[Fetch][{idx}/{total}][retry {attempt}]\")\n",
    "            if attempt < MAX_FETCH_RETRIES:\n",
    "                time.sleep(RETRY_DELAY)\n",
    "                \n",
    "    print(f\"[Fetch error] {idx}/{total}: failed after {MAX_FETCH_RETRIES} retries\")\n",
    "    return url, None\n",
    "\n",
    "def process_article(arg):\n",
    "    url, html = arg\n",
    "    if not html:\n",
    "        return None\n",
    "        \n",
    "    art = Article(url)\n",
    "    art.set_html(html)\n",
    "    \n",
    "    try:\n",
    "        art.parse()\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "    text = art.text or \"\"\n",
    "    title = (art.title or \"\").strip() or \"No title\"\n",
    "    \n",
    "    date, tm = safe_find_datetime(url, html)\n",
    "    \n",
    "    # Return combined data using dictionary unpacking\n",
    "    return {'ticker': TICKER, 'publish_date': date, 'publish_time': tm,\n",
    "             'title': title, 'body_text': text, 'url': url}\n",
    "\n",
    "async def scrape_all(urls):\n",
    "    total = len(urls)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    \n",
    "    # Phase 1: Fetch HTML content from all URLs in parallel\n",
    "    with ThreadPoolExecutor(max_workers=FETCH_WORKERS) as fetch_pool:\n",
    "        # Create fetch tasks and run them through the thread pool\n",
    "        fetch_tasks = [loop.run_in_executor(fetch_pool, fetch_html, u, i+1, total)\n",
    "                       for i, u in enumerate(urls)]\n",
    "        # Wait for all fetch tasks to complete\n",
    "        fetched = await asyncio.gather(*fetch_tasks)\n",
    "\n",
    "    # Phase 2: Process all fetched HTML content in parallel\n",
    "    records = []\n",
    "    with ThreadPoolExecutor(max_workers=PROCESS_WORKERS) as proc_pool:\n",
    "        # Submit processing tasks only for URLs with successful fetches\n",
    "        futures = {\n",
    "            proc_pool.submit(process_article, fr): fr[0]\n",
    "            for fr in fetched if fr[1]  # Skip URLs where HTML is None\n",
    "        }\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for i, fut in enumerate(as_completed(futures), 1):\n",
    "            res = fut.result()\n",
    "            print(f\"[Process][{i}/{total}] {futures[fut]}\")\n",
    "            if res:\n",
    "                records.append(res)\n",
    "                \n",
    "    # Convert results to DataFrame\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# ——— Main entry point function ———\n",
    "def main(links):\n",
    "    df = asyncio.get_event_loop().run_until_complete(scrape_all(links))\n",
    "    return df\n",
    "\n",
    "# Execute the main function if this script is run directly\n",
    "if __name__ == '__main__':\n",
    "    df = main(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8556e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['publish_date', 'publish_time'], ascending=[False,False]).reset_index(drop=True)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d94bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles with empty body_text: 0\n"
     ]
    }
   ],
   "source": [
    "empty_body_count = df[df['body_text'] == ''].shape[0]\n",
    "print(f\"Number of articles with empty body_text: {empty_body_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52396323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY loaded successfully.\n",
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "load_dotenv(\"../SentimentAnalysis/GPT/secret.env\")\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "mongo_connection_string = os.getenv(\"MONGO_CONNECTION_STRING\")\n",
    "\n",
    "if api_key is None:\n",
    "    print(\"Error: GEMINI_API_KEY not found in .env file or environment variables.\")\n",
    "else:\n",
    "    print(\"GEMINI_API_KEY loaded successfully.\")\n",
    "\n",
    "try:\n",
    "    client = MongoClient(mongo_connection_string)\n",
    "    db = client['stock_news_db']\n",
    "    collection = db['news_data']\n",
    "\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b331f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "generation_config = genai.GenerationConfig(\n",
    "        temperature=0,\n",
    ")\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash-preview-04-17\", generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bd63ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "def is_retryable(e) -> bool:\n",
    "    if retry.if_transient_error(e):\n",
    "        return True\n",
    "    elif (isinstance(e, genai.errors.ClientError) and e.code == 429):\n",
    "        return True\n",
    "    elif (isinstance(e, genai.errors.ServerError) and e.code == 503):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "@retry.Retry(predicate=is_retryable)\n",
    "def generate_content_with_rate_limit(prompt):\n",
    "  return model.generate_content(prompt).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf008dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a financial news analyst specializing in stock market impact. Your task is to analyze the provided news article, summarize its core content concisely, determine its sentiment (positive, negative, or neutral), and assess its importance to the specified stock.\n",
    "\n",
    "Here is the news from stock [STOCK] title and body:\n",
    "---\n",
    "[TITLE]\n",
    "---\n",
    "[BODY]\n",
    "---\n",
    "\n",
    "Please provide your analysis in the following format (Don't forget to make space between the sections as shown):\n",
    "\n",
    "**Sentiment:**\n",
    "[Positive / Negative / Neutral]\n",
    "\n",
    "**Summary:**\n",
    "[Your concise summary of the article, typically 2-3 sentences.]\n",
    "\n",
    "**Reasoning for Sentiment:**\n",
    "[Brief explanation (1-2 sentences) of why you categorized the sentiment as such, referencing key points or tone from the article.]\n",
    "\n",
    "**Importance to Stock [STOCK]:**\n",
    "[1-5, where 1 is minimal importance and 5 is very high importance.Answer in 1-5 only, no explanation.] (Answer only in number 1-5)\n",
    "\n",
    "**Reasoning for Importance:**\n",
    "[Brief explanation (1-2 sentences) of why you assigned this importance score, referencing specific details from the article that would impact the stock.]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompting: 100%|██████████| 20/20 [02:04<00:00,  6.24s/it]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Prompting\"): \n",
    "    current_stock = row.get(\"ticker\", \"news\")\n",
    "\n",
    "    filled_prompt = prompt.replace(\"[STOCK]\", current_stock)\n",
    "    filled_prompt = filled_prompt.replace(\"[TITLE]\", row[\"title\"])\n",
    "    filled_prompt = filled_prompt.replace(\"[BODY]\", row[\"body_text\"])\n",
    "\n",
    "    try:\n",
    "        response = generate_content_with_rate_limit(filled_prompt)\n",
    "        finalprediction = response.strip()\n",
    "        if not finalprediction:\n",
    "            print(f\"Row {index}: LLM returned an empty string.\")\n",
    "            predicted.append(\"LLM_EMPTY_RESPONSE\")\n",
    "        else:\n",
    "            predicted.append(finalprediction)\n",
    "    except ValueError as ve:\n",
    "        print(f\"Row {index}: ValueError - {ve}. Appending 'ERROR_VALUE_ERROR'.\")\n",
    "        predicted.append(\"ERROR_VALUE_ERROR\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        if \"429 Too Many Requests\" in str(e) or \"quota\" in str(e).lower():\n",
    "            print(f\"Row {index}: Rate Limit Exceeded or Quota Error - {e}. Appending 'ERROR_RATE_LIMIT'.\")\n",
    "            predicted.append(\"ERROR_RATE_LIMIT\")\n",
    "        elif \"safety\" in str(e).lower() or \"blocked\" in str(e).lower():\n",
    "             print(f\"Row {index}: Content Safety/Blocked - {e}. Appending 'ERROR_SAFETY_BLOCKED'.\")\n",
    "             predicted.append(\"ERROR_SAFETY_BLOCKED\")\n",
    "        else:\n",
    "            print(f\"Row {index}: Unexpected Error - {e}. Appending 'ERROR_UNEXPECTED'.\")\n",
    "            predicted.append(\"ERROR_UNEXPECTED\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20b6b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted = np.array(predicted)\n",
    "df[\"predicted\"] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df145704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = df[\"predicted\"].apply(lambda x: x.split(\"\\n\")[1].strip() if len(x.split(\"\\n\")) > 1 else None)\n",
    "df[\"importance\"] = df[\"predicted\"].apply(lambda x: x.split(\"\\n\")[10].strip() if len(x.split(\"\\n\")) > 10 else None)\n",
    "df[\"summary\"] = df[\"predicted\"].apply(lambda x: x.split(\"\\n\")[4].strip() if len(x.split(\"\\n\")) > 4 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de8ae451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentiment'].isin(['Positive', 'Negative', 'Neutral'])]\n",
    "df = df[df['importance'].isin(['1', '2', '3', '4', '5'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c97e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.0-flash-001\", generation_config=generation_config)\n",
    "prompt = \"\"\"Translate the following English sentence to Thai. Do not translate proper nouns, company names, product names, abbreviations, or technical terms — keep them in English. Do not provide any explanation, just the translation.\n",
    "[TEXT]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "027e30a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompting: 100%|██████████| 20/20 [01:14<00:00,  3.71s/it]\n"
     ]
    }
   ],
   "source": [
    "translate = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Prompting\"): \n",
    "\n",
    "    filled_prompt = prompt.replace(\"[TEXT]\", row[\"summary\"])\n",
    "\n",
    "    try:\n",
    "        response = generate_content_with_rate_limit(filled_prompt)\n",
    "        finalprediction = response.strip()\n",
    "        if not finalprediction:\n",
    "            print(f\"Row {index}: LLM returned an empty string.\")\n",
    "            translate.append(\"LLM_EMPTY_RESPONSE\")\n",
    "        else:\n",
    "            translate.append(finalprediction)\n",
    "    except ValueError as ve:\n",
    "        print(f\"Row {index}: ValueError - {ve}. Appending 'ERROR_VALUE_ERROR'.\")\n",
    "        translate.append(\"ERROR_VALUE_ERROR\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        if \"429 Too Many Requests\" in str(e) or \"quota\" in str(e).lower():\n",
    "            print(f\"Row {index}: Rate Limit Exceeded or Quota Error - {e}. Appending 'ERROR_RATE_LIMIT'.\")\n",
    "            translate.append(\"ERROR_RATE_LIMIT\")\n",
    "        elif \"safety\" in str(e).lower() or \"blocked\" in str(e).lower():\n",
    "             print(f\"Row {index}: Content Safety/Blocked - {e}. Appending 'ERROR_SAFETY_BLOCKED'.\")\n",
    "             translate.append(\"ERROR_SAFETY_BLOCKED\")\n",
    "        else:\n",
    "            print(f\"Row {index}: Unexpected Error - {e}. Appending 'ERROR_UNEXPECTED'.\")\n",
    "            translate.append(\"ERROR_UNEXPECTED\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b227831",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = current_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b07fcf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'predicted' in df.columns:\n",
    "    df.drop(columns=['predicted'], inplace=True)\n",
    "if 'body_text' in df.columns:\n",
    "    df.drop(columns=['body_text'], inplace=True)\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y-%m-%d %H-%M\").strip().replace(' ', '_')\n",
    "filename = f\"Gemini_{TICKER}_{date_time}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbbd4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"translate\"] = translate\n",
    "df.to_csv(f\"Data/{filename}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d2b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted document with id: [ObjectId('685e45e907d123698418ab64'), ObjectId('685e45e907d123698418ab65'), ObjectId('685e45e907d123698418ab66'), ObjectId('685e45e907d123698418ab67'), ObjectId('685e45e907d123698418ab68'), ObjectId('685e45e907d123698418ab69'), ObjectId('685e45e907d123698418ab6a'), ObjectId('685e45e907d123698418ab6b'), ObjectId('685e45e907d123698418ab6c'), ObjectId('685e45e907d123698418ab6d'), ObjectId('685e45e907d123698418ab6e'), ObjectId('685e45e907d123698418ab6f'), ObjectId('685e45e907d123698418ab70'), ObjectId('685e45e907d123698418ab71'), ObjectId('685e45e907d123698418ab72'), ObjectId('685e45e907d123698418ab73'), ObjectId('685e45e907d123698418ab74'), ObjectId('685e45e907d123698418ab75'), ObjectId('685e45e907d123698418ab76'), ObjectId('685e45e907d123698418ab77')]\n"
     ]
    }
   ],
   "source": [
    "complete_dict=df.to_dict(orient='records')\n",
    "\n",
    "result = collection.insert_many(complete_dict,ordered=True)\n",
    "print(f\"Successfully inserted document with id: {result.inserted_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2445b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to be passed to Streamlit: ../CompletePipeline/Data/Gemini_TSLA_2025-06-27_14-19.csv\n"
     ]
    }
   ],
   "source": [
    "data_filepath_for_streamlit = os.path.join(\"..\", \"CompletePipeline\", \"Data\", filename)\n",
    "\n",
    "print(f\"Path to be passed to Streamlit: {data_filepath_for_streamlit}\")\n",
    "\n",
    "#!streamlit run ../Visualization/stock_app.py \"{data_filepath_for_streamlit}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69f69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>importance</th>\n",
       "      <th>summary</th>\n",
       "      <th>translate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2025-06-27</td>\n",
       "      <td>00:16</td>\n",
       "      <td>Chinese EV shares fall as Xiaomi YU7 launch he...</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>4</td>\n",
       "      <td>Chinese electric vehicle stocks fell after Xia...</td>\n",
       "      <td>หุ้นรถยนต์ไฟฟ้าของจีนร่วงลงหลังจาก Xiaomi เปิด...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>22:23</td>\n",
       "      <td>Xiaomi shares hit record high on strong YU7 EV...</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>5</td>\n",
       "      <td>Xiaomi's shares reached a record high followin...</td>\n",
       "      <td>หุ้นของ Xiaomi ทำสถิติสูงสุดเป็นประวัติการณ์หล...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>21:44</td>\n",
       "      <td>Bumper orders for Xiaomi’s new SUV heighten th...</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>5</td>\n",
       "      <td>Xiaomi's new YU7 electric SUV received excepti...</td>\n",
       "      <td>รถ SUV ไฟฟ้า YU7 รุ่นใหม่ของ Xiaomi ได้รับคำสั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>17:09</td>\n",
       "      <td>Trading Day: Markets ’run it hot’ By Reuters</td>\n",
       "      <td>https://www.investing.com/news/economy-news/tr...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>5</td>\n",
       "      <td>The article analyzes the current market rally,...</td>\n",
       "      <td>บทความนี้วิเคราะห์ current market rally ที่ขับ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2025-06-26</td>\n",
       "      <td>15:24</td>\n",
       "      <td>Pony AI stock surges after NYT reports Uber-Ka...</td>\n",
       "      <td>https://www.investing.com/news/stock-market-ne...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>Uber is reportedly in preliminary talks with f...</td>\n",
       "      <td>มีรายงานว่า Uber อยู่ในระหว่างการเจรจาเบื้องต้...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker publish_date publish_time  \\\n",
       "0   TSLA   2025-06-27        00:16   \n",
       "1   TSLA   2025-06-26        22:23   \n",
       "2   TSLA   2025-06-26        21:44   \n",
       "3   TSLA   2025-06-26        17:09   \n",
       "4   TSLA   2025-06-26        15:24   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chinese EV shares fall as Xiaomi YU7 launch he...   \n",
       "1  Xiaomi shares hit record high on strong YU7 EV...   \n",
       "2  Bumper orders for Xiaomi’s new SUV heighten th...   \n",
       "3       Trading Day: Markets ’run it hot’ By Reuters   \n",
       "4  Pony AI stock surges after NYT reports Uber-Ka...   \n",
       "\n",
       "                                                 url sentiment importance  \\\n",
       "0  https://www.investing.com/news/stock-market-ne...  Negative          4   \n",
       "1  https://www.investing.com/news/stock-market-ne...  Negative          5   \n",
       "2  https://www.investing.com/news/stock-market-ne...  Negative          5   \n",
       "3  https://www.investing.com/news/economy-news/tr...  Positive          5   \n",
       "4  https://www.investing.com/news/stock-market-ne...   Neutral          4   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Chinese electric vehicle stocks fell after Xia...   \n",
       "1  Xiaomi's shares reached a record high followin...   \n",
       "2  Xiaomi's new YU7 electric SUV received excepti...   \n",
       "3  The article analyzes the current market rally,...   \n",
       "4  Uber is reportedly in preliminary talks with f...   \n",
       "\n",
       "                                           translate  \n",
       "0  หุ้นรถยนต์ไฟฟ้าของจีนร่วงลงหลังจาก Xiaomi เปิด...  \n",
       "1  หุ้นของ Xiaomi ทำสถิติสูงสุดเป็นประวัติการณ์หล...  \n",
       "2  รถ SUV ไฟฟ้า YU7 รุ่นใหม่ของ Xiaomi ได้รับคำสั...  \n",
       "3  บทความนี้วิเคราะห์ current market rally ที่ขับ...  \n",
       "4  มีรายงานว่า Uber อยู่ในระหว่างการเจรจาเบื้องต้...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
